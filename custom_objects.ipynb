{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=0.1, **kwargs):\n",
    "        self.threshold= threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_error = tf.square(error) / 2\n",
    "        linear_error = self.threshold * tf.abs(error) - self.threshold **2 / 2\n",
    "        return tf.where(is_small_error, squared_error, linear_error)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regulaizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def call(self, weights):\n",
    "        return tf.reduce_sum((tf.abs(self.factor * weights)))\n",
    "    def get_config(self):\n",
    "        return{'factor' : self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn\n",
    "\n",
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.function = create_huber()\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.function(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_add(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config, 'threshold' : self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x : tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', shape=[batch_input_shape[-1], self.units], initializer='glorot_normal')\n",
    "        self.bias = self.add_weight(name='bias', shape=[self.units], initializer='zeros')\n",
    "        super().build(batch_input_shape)\n",
    "    def call(self, x):\n",
    "        return self.activation(x @ self.kernel + self.bias)\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape.aslist()[-1] + self.units)\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return{**base_config, 'units':self.units, 'activation':keras.activation.serialize(self.activation)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, std, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.std = std\n",
    "    def call(self, x, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(x), stddev= self.std)\n",
    "            return x +noise\n",
    "        if not training:\n",
    "            return x\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, layers, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(units, activation='selu', kernel_initializer='lecun_normal') for _ in range(layers)]\n",
    "    def call(self, input):\n",
    "        z = input\n",
    "        for layer in self.hidden:\n",
    "            z = layer(z)\n",
    "        return z +input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps=0.001, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.alpha = self.add_weight(\n",
    "            name=\"alpha\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"ones\")\n",
    "        self.beta = self.add_weight(\n",
    "            name=\"beta\", shape=batch_input_shape[-1:],\n",
    "            initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # must be at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        return self.alpha * (X - mean) / (tf.sqrt(variance + self.eps)) + self.beta\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"eps\": self.eps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthWiseMaxPooling(keras.layers.Layer):\n",
    "    def __init__(self, pool_size, strides=None, padding='VALID', **kwargs):\n",
    "        if strides is None:\n",
    "            strides = pool_size\n",
    "        self.pool_size = pool_size\n",
    "        self.padding = padding\n",
    "        self.strides = strides\n",
    "        super().__init__(**kwargs)\n",
    "    def calls(self, inputs):\n",
    "        return tf.nn.max_pool(inputs, ksize=(1,1,1,self.pool_size), strides=(1,1,1,self.pool_size), padding= self.padding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthWiseAvgPooling(keras.layers.Layer):\n",
    "    def __init__(self, pool_size, strides=None, padding='VALID', **kwargs):\n",
    "        if strides is None:\n",
    "            strides = pool_size\n",
    "        self.pool_size = pool_size\n",
    "        self.padding = padding\n",
    "        self.strides = strides\n",
    "        super().__init__(**kwargs)\n",
    "    def calls(self, inputs):\n",
    "        return tf.nn.avg_pool(inputs, ksize=(1,1,1,self.pool_size), strides=(1,1,1,self.pool_size), padding= self.padding )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "default_layer = partial(keras.layers.Conv2D, kernel_size=3, padding='SAME', strides=1, use_bias=False)\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers= [\n",
    "            default_layer(filters, strides=strides),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            default_layer(filters),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                default_layer(filters, strides=strides),\n",
    "                keras.layers.BatchNormalization()\n",
    "            ]\n",
    "    def call(self, inputs):\n",
    "        z = inputs\n",
    "        for layer in self.main_layers:\n",
    "            z = layer(z)\n",
    "        skip_z = inputs\n",
    "        for skip_layer in self.skip_layers:\n",
    "            skip_z = skip_layer(skip_z)\n",
    "        return self.activation(z + skip_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LNSimpleRNN(keras.layers.Layer):\n",
    "    def __init__(self, units, activation='elu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_size = units\n",
    "        self.state_size = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.layer_normalization = keras.layers.LayerNormalization\n",
    "        self.simple_rnn_cell = keras.layers.SimpleRNNCell(units,\n",
    "                                                          activation=None)\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if inputs is not None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "            dtype = inputs.dtype\n",
    "        return [tf.zeros([batch_size, self.state_size], dtype=dtype)]\n",
    "    def call(self, inputs, states):\n",
    "        outputs, new_states = self.simple_rnn_cell(inputs, states)\n",
    "        norm_outputs = self.activation(self.layer_norm(outputs))\n",
    "        return norm_outputs, [norm_outputs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
